Pending main tasks to date:

    Tim cach thay the input cho hai cai network thanh ba ma tran (hoac nhieu hon)

    Thay the cai input (chac mat kha kha thoi gian)

    Ap hai model con lai vao

    Train -> xuat ket qua -> thong ke lai

    cho truong lam code xong tich hop vao



Hoan thanh not cang som cang tot: 

    train with no gradient - done

    The tf.no_gradient() function is used in TensorFlow to specify operations for which gradients 
    should not be computed during backpropagation. This can be useful in scenarios where you have parts 
    of your computation graph that don't require gradients, which can potentially speed up the computation 
    by skipping unnecessary gradient computations. In the context of your code, 
    it seems you're using a Keras model for training your DQN agent, which internally uses TensorFlow. 
    However, I don't see any explicit TensorFlow operations in your code snippet. 
    Instead, you're mostly using high-level Keras functions and classes. 
    If you were to use TensorFlow operations directly, 
    you could potentially benefit from tf.no_gradient() in specific parts of your computation where gradients are not needed. 
    For example, if you have some custom operations or loss functions implemented using TensorFlow operations, 
    you could use tf.no_gradient() to indicate that gradients for those operations should not be computed.

    => hau het code su dung ham Keras bac cao, ko co cac tac vu tinh toan gradient chi tiet
    => ko can su dung no_gradient

    ghi nhan state vao csv roi moi xuat hinh -> nhanh hon xuat hinh tai tung state

    => Done. Thuc hien ghi nhan cua evaluation. ghi nhan tung buoc cua state vao file csv roi xuat hinh + gif tu csv




Tiep tuc thuc hien toi truoc khi bao cao:

    Tim cach thay the input cho hai cai network thanh ba ma tran (hoac nhieu hon)
    => 26/03 Da design duoc so do tam thoi cua network moi bang code (ddqn_network_test_3), chua biet truyen input vao nhu the nao

    Thay the cai input (chac mat kha kha thoi gian)

    Tinh cac ti le FN FP TN TP ?
    => Hoc tang cuong khong su dung cac ti le nay
    => ap dung vao he thong NMS cua Truong nhu tham so uncertainty

Kho khan + thac mac:

    Moi model chi chay duoc voi 1 so node nhat dinh => can qua nhieu model cho cac tinh huong khac nhau?

    Lam the nao de chi su dung 1 model du doan duoc nhieu so luong node (mang neuron)?

    Dau ra qua lon (10 node K vÃ  5 node M cho ra 30240 to hop hanh dong co the thuc hien)=> can thu nho lai

    => Lam the nao de toi uu cach luu tru va truy xuat hanh dong trong bang Q-values (DDQN)


Pending main tasks to date:

    Tim cach thay the input cho hai cai network thanh ba ma tran (hoac nhieu hon)

    Thay the cai input (chac mat kha kha thoi gian)

    Ap hai model con lai vao

    Train -> xuat ket qua -> thong ke lai

    cho truong lam code xong tich hop vao

    Luu mot ban attacker cu (random) de thuc hien so sanh voi attacker moi (weighted random)



Hoan thanh not cang som cang tot: 

    mang 10 node 3 honeypot (Dat cang it cang tot - bai toan phan bo honeypot tren tai nguyen gioi han) ->  Giai quyet vu out of bound for axis

    - Luu y: CO DINH ENTRYPOINT (Da co dinh)

    => Phat hien 1: neu huan luyen mang network voi so decoy thap hon, qua trinh evaluation co the dien ra bth ma ko bi out of bound

    => Can huan luyen cho mang neuron voi cac truong hop decoy it -> Dang tien hanh huan luyen tu 1 decoy -> K/2 decoy

    Tinh dsp trong 2 TH: random attacker voi random weight attacker

    => lam truoc 1 so do dsp: eval cho no chay n step roi dung lai => dat moc limit
    => cu khoang 50 episode trich so step + tinh diem dsp cho 50 episode do = so episode co reward > 1 / tong so episode
    => so step | dsp tai step do

    => Phan FNR FPR se cho Truong hoan thanh not mang, sau do trien khai va so sanh giua cac FNR va FPR khac nhau
    






Tiep tuc thuc hien toi truoc khi bao cao:

    => PPO co the giai quyet van de action space lon

    
06/04/2024
idea: tao mot cai action space ben trong NetworkHoneypotEnv la mot cai ndarray chua tat ca
may cai hanh dong gen ra theo y tuong cua thay
=> tao env moi => code cua thay gen ra tat ca hanh dong co the thuc hien => luu vao NetworkHoneypotEnv nhu mot ndarray luon (giong Env cua gym)
=> phai dinh nghia lai action trong NetworkHoneypotEnv

cong viec ngay mai:
- thuc hien idea o tren: sua lai action trong NetworkHoneypotEnv
- lam tiep phan sarsa
- neu duoc coi thu may cai static + random deployment policy



Ket luan 06/04
da hoan thanh chuyen doi action space => co the ap dung vao cac model khac
dat ra lai cau hoi: voi moi so luong decoy duoc cap la mot model khac nhau, do action space khac nhau hoan toan
=> can qua nhieu model? khong the train 3 decoy va setup tren 2 decoy duoc
=> Da tim ra ly do bi out of bound: do khi train tu 1 node do len, action space se banh rong ra dan dan 
=> nen khi train toi K/2 node thi action space -> output network size qua lon cho 1 node
=> output network se predict hanh dong thu 210 (gia su) ma action space cua 1 node chi la khoang 20 - 21 (gia su)
=> out of bound
Giai phap: train chay nguoc lai tu K/2 ve 1 =>  output network size thu nho dan cho den 1 node

=> Toc do chay cua action moi nhanh gap doi ma tran K*M cu (code cu tren linux VM1)

-----------------------------------------------
08-09/04 hiatus
-----------------------------------------------

Chay evaluation tai tung so step nhat dinh de xuat ra dsp chu ko di theo episode (2000, 5000, 10000, 20000)
=> code driver keo theo code eval chay

CONG VIEC NGAY MAI 10/04/2024

Chay 30000+ steps (9000 - 10000 episodes): ddqn
Random allocation: 10 scenarios
Static policy: 21 scenarios =>  the size of the action space is 21. 
=> Static policy = nCr => la bo tri tung action rieng le trong action space xong cho chay 50 episode eval
=> Xong danh gia coi static policy nao la dsp cao nhat

XEM XET CHAY 10000 EPISODE TREN MAY linux


=> Qua eval lam truoc 3 cai loop 50 ep cho 3 loai policy ddqn + static + randyn
=> Da hoan thanh, xuat duoc so do dsp cho static + randyn va traning time + dsp cho ddqn


Lam tiep 3 mang matrix
Luu y: giu nguyen epss du ntpg danh so 0 => dai dien cho epss escalate privilege
Khong su dung lop Dense do dense la mang 1 chieu (tim cach chuyen qua convolutional neural network)




Cong viec toi T3:
- Thuc hien deploy/fix mang network 3 matrix moi vao mo hinh
- Viet bao cao cong viec tien do + du kien tuong lai (lay may cai todo de viet + de cuong)




Cong viec du kien tuong lai
- Tiep tuc nghien cuu + thiet ke hai mo hinh SARSA + PPO
- Tim cach thuc hien inference tren he thong de dua he thong sang giai doan deployment